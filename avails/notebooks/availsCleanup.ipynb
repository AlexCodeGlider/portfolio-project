{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:28:33.879033Z",
     "start_time": "2021-01-12T01:28:33.229085Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "def tidy_split(df, column, sep=',', keep=False):\n",
    "    \"\"\"\n",
    "    Split the values of a column and expand so the new DataFrame has one split\n",
    "    value per row. Filters rows where the column is missing.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the column to split and expand\n",
    "    column : str\n",
    "        the column to split and expand\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "    keep : bool\n",
    "        whether to retain the presplit value as it's own row\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value.strip())\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df\n",
    "\n",
    "def cleanup(df, suffix=''):\n",
    "    df['Non-Exclusive Date'] = df['Non-Exclusive Date'].replace('NOT AVAIL', np.nan).astype('datetime64')\n",
    "    df['Non-Exclusive Date'] = df.apply(lambda x: dt.date.today() if x['Available?'] == 'Avail NE' else x['Non-Exclusive Date'], axis=1)\n",
    "    max_prev_sale_enddate = df['Previous Sale Activity'].str.extractall(r'(\\d{2}[-]\\w{3}[-]\\d{4})').astype('datetime64').reset_index().groupby('level_0')[0].max()\n",
    "    max_prev_sale_enddate = max_prev_sale_enddate + pd.DateOffset(1)\n",
    "    df['max_prev_sale_enddate'] = max_prev_sale_enddate\n",
    "    df['Exclusive Date'] = df['Exclusive Date'].replace(['NOT AVAIL', 'NOT ACQ'], np.nan).astype('datetime64')\n",
    "    max_prev_sale_enddate = df[['Exclusive Date', 'max_prev_sale_enddate']].max(axis=1)\n",
    "    mask = ~df['Exclusive Date'].isna()\n",
    "    df.loc[mask, 'Exclusive Date'] = max_prev_sale_enddate\n",
    "    mask = df['Holdback'] <= dt.datetime.today()\n",
    "    df['Holdback'].loc[mask] = pd.NaT\n",
    "    mask = (df['Non-Exclusive Date'] < df['Exclusive Date']) & (df['Non-Exclusive Date'] > dt.datetime.today())\n",
    "    df['Available?'].loc[mask] = df['Non-Exclusive Date'].loc[mask]\n",
    "    df['First Run or Library'] = df['Is Reissue?'].fillna('First Run')\n",
    "    df['First Run or Library'] = df['First Run or Library'].map({'Yes': 'Library', 'First Run': 'First Run'})\n",
    "\n",
    "    sale_activity = tidy_split(df, 'Previous Sale Activity', sep='\\n', keep=False)\n",
    "    sale_activity['Previous Sale Activity'] = sale_activity['Previous Sale Activity'].str.replace('.', '')\n",
    "    sale_activity_enddates = sale_activity['Previous Sale Activity'].str[-11:]\n",
    "    date_dict = {'ene': '01', 'feb': '02', 'mar': '03', 'abr': '04', 'may':'05', 'jun': '06', 'jul': '07', 'ago': '08', 'sep':'09', 'oct': '10', 'nov': '11', 'dic': '12'}\n",
    "    sale_activity_enddates = sale_activity_enddates.replace(date_dict, regex=True)\n",
    "    sale_activity_enddates = sale_activity_enddates.replace('own-Unknown', np.nan).astype('datetime64')\n",
    "    sale_activity['end_dates'] = sale_activity_enddates\n",
    "    sale_activity['end_dates'].fillna(sale_activity['Acq. Expires'], inplace=True)\n",
    "    sale_activity['client'] = sale_activity['Previous Sale Activity'].str[:-25]\n",
    "    sale_activity = sale_activity.pivot_table(index='Unique Id', values='end_dates', columns='client', aggfunc=max)\n",
    "\n",
    "\n",
    "    df = df.join(sale_activity, on='Unique Id', how='left').sort_values(by='Unique Id')\n",
    "\n",
    "    df.columns = list(df.columns[:13]) + [str(col) + suffix for col in df.columns[13:]]\n",
    "    return df, [str(col) + suffix for col in sale_activity.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:57:43.442465Z",
     "start_time": "2021-01-12T01:57:43.399581Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(df, sales, screeners, ratings):\n",
    "    metadata = ['Title', 'Genre', 'Cast Member', 'Year Completed', 'Director',\n",
    "                        'Project Type', 'Synopsis', 'Unique Id', 'Website', 'Original Format',\n",
    "                        'Dialogue Language', 'Subtitle Language']\n",
    "    \n",
    "    metadata_df = df[metadata].drop_duplicates().copy()\n",
    "    \n",
    "    agg_dict = {'Region': lambda x: ' & '.join(x)}\n",
    "\n",
    "    for col in df.columns:\n",
    "        for colname in ['First Run or Library', 'Available', 'Holdback', 'Note', 'Acq. Expires', 'Previous Sale Activity']:\n",
    "            if colname in col:\n",
    "                agg_dict[col] = 'first'\n",
    "    \n",
    "    for sale in sales:\n",
    "        agg_dict[sale] = 'first'\n",
    "    \n",
    "    for col in df.columns: \n",
    "        if 'Exclusive Date' in col:\n",
    "            df[col].fillna(pd.Timestamp.max, inplace=True)\n",
    "    \n",
    "    df = df.groupby(['Unique Id']+[col for col in df.columns if 'Date' in col]).agg(agg_dict).reset_index()\n",
    "\n",
    "    region_mapping = {'Brazil & Latin America excluding Brazil & Mexico & Mexico': 'All Latam',\n",
    "            'Brazil & Mexico & Latin America excluding Brazil & Mexico': 'All Latam',\n",
    "            'Mexico & Brazil & Latin America excluding Brazil & Mexico': 'All Latam',\n",
    "            'Mexico & Latin America excluding Brazil & Mexico & Brazil': 'All Latam',\n",
    "            'Latin America excluding Brazil & Mexico & Mexico & Brazil': 'All Latam',\n",
    "            'Latin America excluding Brazil & Mexico & Brazil & Mexico': 'All Latam',\n",
    "            'Latin America excluding Brazil & Mexico & Mexico': 'Latin America excluding Brazil',\n",
    "            'Mexico & Latin America excluding Brazil & Mexico': 'Latin America excluding Brazil',\n",
    "            'Latin America excluding Brazil & Mexico & Brazil': 'Latin America excluding Mexico',\n",
    "            'Brazil & Latin America excluding Brazil & Mexico': 'Latin America excluding Mexico',\n",
    "             'Brazil': 'Brazil',\n",
    "             'Mexico': 'Mexico',\n",
    "             'Mexico & Brazil': 'Mexico & Brazil',\n",
    "             'Brazil & Mexico': 'Mexico & Brazil',\n",
    "             'Latin America excluding Brazil & Mexico': 'Latin America excluding Brazil & Mexico',}\n",
    "\n",
    "    df['Region'] = df['Region'].map(region_mapping)\n",
    "\n",
    "    df = pd.merge(df, metadata_df, on='Unique Id')\n",
    "\n",
    "    df = pd.merge(df, screeners, on='Unique Id', how='left')\n",
    "\n",
    "    df = pd.merge(df, ratings, on='Unique Id', how='left')\n",
    "\n",
    "    acq_exp_cols = [col for col in df.columns if 'Acq. Expires' in col]\n",
    "    \n",
    "    expiry_dates = df[acq_exp_cols[0]].apply(lambda x: x.date())\n",
    "    \n",
    "    df.drop(acq_exp_cols, axis=1, inplace=True)\n",
    "    df['Acq. Expires'] = expiry_dates\n",
    "\n",
    "    date_cols = [col for col in df.columns if 'Date' in col]\n",
    "\n",
    "    df[date_cols] = df[date_cols].replace({pd.Timestamp.max: pd.NaT})\n",
    "\n",
    "    for col in date_cols:\n",
    "        df[col] = df[col].apply(lambda x: x.date())\n",
    "        df[col] = df[col].apply(lambda x: 'Now' if x == dt.date.today() else x)\n",
    "\n",
    "    df['Year'] = df['Year Completed']\n",
    "        \n",
    "    df[sales] = df[sales].apply(lambda x: x.apply(lambda x: str(x)[:10] if str(x) != 'nan' else ''))\n",
    "\n",
    "    df[[col for col in df.columns if 'Available' in col]] = df[[col for col in df.columns if 'Available' in col]].apply(lambda x: x.apply(lambda x: pd.Timestamp(x) if type(x) == int else x))\n",
    "\n",
    "    df[[col for col in df.columns if 'Available' in col]] = df[[col for col in df.columns if 'Available' in col]].apply(lambda x: x.apply(lambda x: str(x).replace(' 00:00:00', '')))\n",
    "\n",
    "    df[[col for col in df.columns if 'Holdback' in col]] = df[[col for col in df.columns if 'Holdback' in col]].apply(lambda x: x.apply(lambda x: str(x).replace(' 00:00:00', '')))\n",
    "\n",
    "    df = df.apply(lambda x: x.apply(lambda x: '' if str(x) == 'NaT' else x))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:57:52.115749Z",
     "start_time": "2021-01-12T01:57:47.136061Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "svod_avails = pd.read_excel('C:/Users/aleja/Downloads/Availability by Region with Reissues - SVOD (26).xlsx', skiprows=1)\n",
    "svod_avails, svod_sales = cleanup(svod_avails, 'SVOD')\n",
    "\n",
    "ptv_avails = pd.read_excel('C:/Users/aleja/Downloads/Availability by Region with Reissues - Basic Pay TV (26).xlsx', skiprows=1)\n",
    "ptv_avails, ptv_sales = cleanup(ptv_avails, 'PanRegionalPayTV')\n",
    "\n",
    "ptv_local_avails = pd.read_excel('C:/Users/aleja/Downloads/Availability by Region with Reissues - Basic Pay TV (Local) (26).xlsx', skiprows=1)\n",
    "ptv_local_avails, ptv_local_sales = cleanup(ptv_local_avails, 'LocalPayTV')\n",
    "\n",
    "ptv_avails = ptv_avails.merge(ptv_local_avails, on=list(ptv_avails.columns[:13]), how='left')\n",
    "\n",
    "merged_df = ptv_avails.merge(svod_avails, on=list(ptv_avails.columns[:13]), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:57:53.171966Z",
     "start_time": "2021-01-12T01:57:52.692061Z"
    }
   },
   "outputs": [],
   "source": [
    "screeners = pd.read_excel('Z:\\LEDAFILMS\\Alteryx\\Filmtracks\\Project Data ID.xlsx')\n",
    "screeners.dropna(axis=0, subset=['Unique Identifier'], inplace=True)\n",
    "screeners['Unique Id'] = screeners['Unique Identifier'].astype(int)\n",
    "screeners.drop(['Unique Identifier', 'Title', 'Web Site'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:57:54.193116Z",
     "start_time": "2021-01-12T01:57:53.492114Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_excel('Z:\\LEDAFILMS\\Alteryx\\Filmtracks\\Ratings & Titles.xls')\n",
    "ratings.dropna(axis=0, subset=['Unique Identifier'], inplace=True)\n",
    "ratings['Unique Id'] = ratings['Unique Identifier'].astype(int)\n",
    "ratings.drop(['Unique Identifier', 'Title', 'Imdb'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:59:24.043292Z",
     "start_time": "2021-01-12T01:59:24.027336Z"
    }
   },
   "outputs": [],
   "source": [
    "#sales = svod_sales+ptv_sales+ptv_local_sales\n",
    "sales = ptv_sales\n",
    "sales = [sale for sale in sales if not sale.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:59:32.316404Z",
     "start_time": "2021-01-12T01:59:32.127913Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = process(merged_df, sales, screeners, ratings)\n",
    "df = process(ptv_avails, sales, screeners, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T01:58:14.682214Z",
     "start_time": "2021-01-12T01:58:14.656284Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "cols_ordered = ['Project Type', 'Unique Id', 'Title', 'Region', 'Year', 'Genre', 'Cast Member',\n",
    "                            'Director',  'Synopsis', 'Website',\n",
    "                            'Original Format', 'Dialogue Language', 'Subtitle Language',\n",
    "\n",
    "                            'First Run or Library_PanRegionalPayTV',\n",
    "                            'Available?_PanRegionalPayTV', 'Non-Exclusive Date_PanRegionalPayTV',\n",
    "                            'Exclusive Date_PanRegionalPayTV', 'Note_PanRegionalPayTV',\n",
    "                            'Holdback_PanRegionalPayTV',\n",
    "\n",
    "                            'First Run or Library_LocalPayTV',\n",
    "                            'Available?_LocalPayTV', 'Non-Exclusive Date_LocalPayTV',\n",
    "                            'Exclusive Date_LocalPayTV', 'Note_LocalPayTV',\n",
    "                            'Holdback_LocalPayTV',\n",
    "\n",
    "                            'First Run or Library_SVOD',\n",
    "                            'Available?_SVOD', 'Non-Exclusive Date_SVOD',\n",
    "                            'Exclusive Date_SVOD', 'Note_SVOD',\n",
    "                            'Holdback_SVOD',\n",
    "\n",
    "                            'Acq. Expires',\n",
    "                            'Link','Password', 'IMDB Link', 'US Box Office', 'LATAM Box Office', 'USA ',\n",
    "                            'Mexico', 'Brazil', ' Argentina', 'Bolivia', 'Chile', 'Colombia ',\n",
    "                            'Costa Rica', 'Ecuador', 'El Salvador', 'Guatemala', 'Honduras',\n",
    "                            'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'Dominican Republic',\n",
    "                            'Uruguay', 'Venezuela']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T02:00:38.445456Z",
     "start_time": "2021-01-12T02:00:38.423523Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_ordered = ['Project Type', 'Unique Id', 'Title', 'Region', 'Year', 'Genre', 'Cast Member',\n",
    "                            'Director',  'Synopsis', 'Website',\n",
    "                            'Original Format', 'Dialogue Language', 'Subtitle Language',\n",
    "\n",
    "                            'First Run or Library_PanRegionalPayTV',\n",
    "                            'Available?_PanRegionalPayTV', 'Non-Exclusive Date_PanRegionalPayTV',\n",
    "                            'Exclusive Date_PanRegionalPayTV', 'Note_PanRegionalPayTV',\n",
    "                            'Holdback_PanRegionalPayTV',\n",
    "\n",
    "                            'Acq. Expires',\n",
    "                            'Link','Password', 'IMDB Link', 'US Box Office', 'LATAM Box Office', 'USA ',\n",
    "                            'Mexico', 'Brazil', ' Argentina', 'Bolivia', 'Chile', 'Colombia ',\n",
    "                            'Costa Rica', 'Ecuador', 'El Salvador', 'Guatemala', 'Honduras',\n",
    "                            'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'Dominican Republic',\n",
    "                            'Uruguay', 'Venezuela']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T02:00:55.913451Z",
     "start_time": "2021-01-12T02:00:55.495979Z"
    }
   },
   "outputs": [],
   "source": [
    "df[cols_ordered + sales].to_excel('C:/Users/aleja/Documents/Alteryx/Ledafilms Data/Avails/Temp/PanRegionalPayTV avails.xlsx',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
