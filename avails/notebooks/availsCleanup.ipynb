{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-27T16:52:28.312236Z",
     "start_time": "2021-02-27T16:52:27.935949Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-27T18:37:00.321999Z",
     "start_time": "2021-02-27T18:37:00.275518Z"
    }
   },
   "outputs": [],
   "source": [
    "def tidy_split(df, column, sep=',', keep=False):\n",
    "    \"\"\"\n",
    "    Split the values of a column and expand so the new DataFrame has one split\n",
    "    value per row. Filters rows where the column is missing.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the column to split and expand\n",
    "    column : str\n",
    "        the column to split and expand\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "    keep : bool\n",
    "        whether to retain the presplit value as it's own row\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value.strip())\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df\n",
    "\n",
    "def sale_activity(df, suffix=''):\n",
    "    sale_act = tidy_split(df, 'Previous Sale Activity', sep='\\n', keep=False)\n",
    "    sale_act['Previous Sale Activity'] = sale_act['Previous Sale Activity'].str.replace('.', '')\n",
    "    sale_activity_enddates = sale_act['Previous Sale Activity'].str[-11:]\n",
    "    date_dict = {'ene': '01', 'feb': '02', 'mar': '03', 'abr': '04', 'may':'05', 'jun': '06', 'jul': '07', 'ago': '08', 'sep':'09', 'oct': '10', 'nov': '11', 'dic': '12'}\n",
    "    sale_activity_enddates = sale_activity_enddates.replace(date_dict, regex=True)\n",
    "    sale_activity_enddates = sale_activity_enddates.replace('own-Unknown', np.nan).astype('datetime64')\n",
    "    sale_act['end_dates'] = sale_activity_enddates\n",
    "    sale_act['end_dates'].fillna(sale_act['Acq. Expires'], inplace=True)\n",
    "    sale_act['client'] = sale_act['Previous Sale Activity'].str[:-25]\n",
    "    sale_act = sale_act.pivot_table(index='Unique Id', values='end_dates', columns='client', aggfunc=max)\n",
    "    return df.join(sale_act, on='Unique Id', how='left').sort_values(by='Unique Id'), [str(col) + suffix for col in sale_act.columns]\n",
    "\n",
    "def cleanup(df, suffix=''):\n",
    "    date_map = {'NOW': today, 'NOT AVAIL': pd.NaT, 'NOT ACQ': pd.NaT}\n",
    "    df['Non-Exclusive Date'] = df['Non-Exclusive Date'].replace(date_map)\n",
    "    df['Exclusive Date'] = df['Exclusive Date'].replace(date_map)\n",
    "    df['Non-Exclusive Date'] = df.apply(lambda x: today if x['Available?'] == 'Avail NE' else x['Non-Exclusive Date'], axis=1)\n",
    "    max_prev_sale_enddate = df['Previous Sale Activity'].str.extractall(r'(\\d{2}\\-\\w{3}(\\.)?\\-\\d{4})').replace('.', '')\n",
    "    date_dict = {'ene': '01', 'feb': '02', 'mar': '03', 'abr': '04', 'may':'05', 'jun': '06', 'jul': '07', 'ago': '08', 'sep':'09', 'oct': '10', 'nov': '11', 'dic': '12'}\n",
    "    max_prev_sale_enddate = max_prev_sale_enddate.replace(date_dict, regex=True)\n",
    "    max_prev_sale_enddate = max_prev_sale_enddate.astype('datetime64[ns]').reset_index().groupby('level_0')[0].max()\n",
    "    max_prev_sale_enddate = max_prev_sale_enddate + pd.DateOffset(1)\n",
    "    df['max_prev_sale_enddate'] = max_prev_sale_enddate\n",
    "    max_prev_sale_enddate = df[['Exclusive Date', 'max_prev_sale_enddate']].max(axis=1)\n",
    "    df['Exclusive Date'] = max_prev_sale_enddate\n",
    "    df['Holdback'] = df['Holdback'].apply(lambda x: pd.Timestamp.date(x))\n",
    "    mask = df['Holdback'] <= today\n",
    "    df['Holdback'].loc[mask] = pd.NaT\n",
    "    df['Non-Exclusive Date'] = df['Non-Exclusive Date'].apply(lambda x: pd.Timestamp.date(x))\n",
    "    df['Exclusive Date'] = df['Exclusive Date'].apply(lambda x: pd.Timestamp.date(x))\n",
    "    mask = (df['Non-Exclusive Date'] < df['Exclusive Date']) & (df['Non-Exclusive Date'] > today)\n",
    "    df['Available?'].loc[mask] = df['Non-Exclusive Date'].loc[mask]\n",
    "    df['Available?'] = df['Available?'].apply(lambda x: pd.Timestamp.date(pd.Timestamp(x)) if type(x) == int else x)\n",
    "    df['First Run or Library'] = df['Is Reissue?'].fillna('First Run')\n",
    "    df['First Run or Library'] = df['First Run or Library'].map({'Yes': 'Library', 'First Run': 'First Run'})\n",
    "\n",
    "    df, sales = sale_activity(df, suffix)\n",
    "\n",
    "    df.columns = list(df.columns[:13]) + [str(col) + suffix for col in df.columns[13:]]\n",
    "    return df, sales\n",
    "\n",
    "def process(df, sales, screeners, ratings):\n",
    "    metadata = ['Title', 'Genre', 'Cast Member', 'Year Completed', 'Director',\n",
    "                        'Project Type', 'Synopsis', 'Unique Id', 'Website', 'Original Format',\n",
    "                        'Dialogue Language', 'Subtitle Language']\n",
    "\n",
    "    metadata_df = df[metadata].drop_duplicates().copy()\n",
    "\n",
    "    agg_dict = {'Region': lambda x: ' & '.join(x)}\n",
    "\n",
    "    for col in df.columns:\n",
    "        for colname in ['First Run or Library', 'Available', 'Holdback', 'Note', 'Acq. Expires', 'Previous Sale Activity']:\n",
    "            if colname in col:\n",
    "                agg_dict[col] = 'first'\n",
    "\n",
    "    sales = [sale for sale in sales if not sale.startswith('_')]\n",
    "\n",
    "    for sale in sales:\n",
    "        agg_dict[sale] = 'first'\n",
    "\n",
    "    for col in df.columns:\n",
    "        if 'Exclusive Date' in col:\n",
    "            df[col].fillna(pd.Timestamp.max, inplace=True)\n",
    "\n",
    "    df = df.groupby(['Unique Id']+[col for col in df.columns if 'Date' in col]).agg(agg_dict).reset_index()\n",
    "\n",
    "    region_mapping = {'Brazil & Latin America excluding Brazil & Mexico & Mexico': 'All Latam',\n",
    "            'Brazil & Mexico & Latin America excluding Brazil & Mexico': 'All Latam',\n",
    "            'Mexico & Brazil & Latin America excluding Brazil & Mexico': 'All Latam',\n",
    "            'Mexico & Latin America excluding Brazil & Mexico & Brazil': 'All Latam',\n",
    "            'Latin America excluding Brazil & Mexico & Mexico & Brazil': 'All Latam',\n",
    "            'Latin America excluding Brazil & Mexico & Brazil & Mexico': 'All Latam',\n",
    "            'Latin America excluding Brazil & Mexico & Mexico': 'Latin America excluding Brazil',\n",
    "            'Mexico & Latin America excluding Brazil & Mexico': 'Latin America excluding Brazil',\n",
    "            'Latin America excluding Brazil & Mexico & Brazil': 'Latin America excluding Mexico',\n",
    "            'Brazil & Latin America excluding Brazil & Mexico': 'Latin America excluding Mexico',\n",
    "             'Brazil': 'Brazil',\n",
    "             'Mexico': 'Mexico',\n",
    "             'Mexico & Brazil': 'Mexico & Brazil',\n",
    "             'Brazil & Mexico': 'Mexico & Brazil',\n",
    "             'Latin America excluding Brazil & Mexico': 'Latin America excluding Brazil & Mexico',}\n",
    "\n",
    "    df['Region'] = df['Region'].map(region_mapping)\n",
    "    df = pd.merge(df, metadata_df, on='Unique Id')\n",
    "    df = pd.merge(df, screeners, on='Unique Id', how='left')\n",
    "    df = pd.merge(df, ratings, on='Unique Id', how='left')\n",
    "    acq_exp_cols = [col for col in df.columns if 'Acq. Expires' in col]\n",
    "    expiry_dates = df[acq_exp_cols[0]].apply(lambda x: pd.Timestamp.date(x))\n",
    "    df.drop(acq_exp_cols, axis=1, inplace=True)\n",
    "    df['Acq. Expires'] = expiry_dates\n",
    "    date_cols = [col for col in df.columns if 'Date' in col]\n",
    "    df[date_cols] = df[date_cols].replace({pd.Timestamp.max: pd.NaT})\n",
    "\n",
    "    for col in date_cols:\n",
    "        mask = df[col] >= df['Acq. Expires']\n",
    "        df[col].loc[mask] = pd.NaT\n",
    "        df[col] = df[col].apply(lambda x: 'Now' if x == today else x)\n",
    "        \n",
    "    df['Year'] = df['Year Completed']\n",
    "    df[sales] = df[sales].apply(lambda x: x.apply(lambda x: str(x)[:10] if str(x) != 'nan' else ''))\n",
    "    df[[col for col in df.columns if 'Available' in col]] = df[[col for col in df.columns if 'Available' in col]].apply(lambda x: x.apply(lambda x: pd.Timestamp.date(pd.Timestamp(x)) if type(x) == int else x))\n",
    "    df[[col for col in df.columns if 'Available' in col]] = df[[col for col in df.columns if 'Available' in col]].apply(lambda x: x.apply(lambda x: str(x).replace(' 00:00:00', '')))\n",
    "    df[[col for col in df.columns if 'Holdback' in col]] = df[[col for col in df.columns if 'Holdback' in col]].apply(lambda x: x.apply(lambda x: str(x).replace(' 00:00:00', '')))\n",
    "    df[[col for col in df.columns if 'Date' in col]] = df[[col for col in df.columns if 'Date' in col]].apply(lambda x: x.apply(lambda x: str(x).replace(' 00:00:00', '')))\n",
    "    df = df.apply(lambda x: x.apply(lambda x: '' if (str(x) == 'NaT' or str(x) == 'None' or str(x) == '0001-01-01') else x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-27T18:37:03.007003Z",
     "start_time": "2021-02-27T18:37:01.533614Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandroleda/opt/anaconda3/envs/generalCondaEnv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "<ipython-input-46-82f8b6944bc7>:39: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  sale_act['Previous Sale Activity'] = sale_act['Previous Sale Activity'].str.replace('.', '')\n",
      "/Users/alejandroleda/opt/anaconda3/envs/generalCondaEnv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "<ipython-input-46-82f8b6944bc7>:39: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  sale_act['Previous Sale Activity'] = sale_act['Previous Sale Activity'].str.replace('.', '')\n",
      "/Users/alejandroleda/opt/anaconda3/envs/generalCondaEnv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "<ipython-input-46-82f8b6944bc7>:39: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  sale_act['Previous Sale Activity'] = sale_act['Previous Sale Activity'].str.replace('.', '')\n",
      "/Users/alejandroleda/opt/anaconda3/envs/generalCondaEnv/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "svod_avails = pd.read_excel('/Users/alejandroleda/Downloads/Availability by Region with Reissues - SVOD.xlsx', skiprows=1)\n",
    "\n",
    "ptv_avails = pd.read_excel('/Users/alejandroleda/Downloads/Availability by Region with Reissues - Basic Pay TV.xlsx', skiprows=1)\n",
    "\n",
    "ptv_local_avails = pd.read_excel('/Users/alejandroleda/Downloads/Availability by Region with Reissues - SVOD.xlsx', skiprows=1)\n",
    "\n",
    "screeners = pd.read_excel('/Users/alejandroleda/Documents/Ledafilms/Misc/Temp/Project Data ID.xlsx')\n",
    "screeners.dropna(axis=0, subset=['Unique Identifier'], inplace=True)\n",
    "screeners['Unique Id'] = screeners['Unique Identifier'].astype(int)\n",
    "screeners.drop(['Unique Identifier', 'Title', 'Web Site'], axis = 1, inplace=True)\n",
    "\n",
    "ratings = pd.read_excel('/Users/alejandroleda/Documents/Ledafilms/Misc/Temp/Ratings & Titles.xls')\n",
    "ratings.dropna(axis=0, subset=['Unique Identifier'], inplace=True)\n",
    "ratings['Unique Id'] = ratings['Unique Identifier'].astype(int)\n",
    "ratings.drop(['Unique Identifier', 'Title', 'Imdb'], axis = 1, inplace=True)\n",
    "\n",
    "today = pd.Timestamp.date(pd.Timestamp.today())\n",
    "\n",
    "svod_avails, svod_sales = cleanup(svod_avails, '_SVOD')\n",
    "ptv_avails, ptv_sales = cleanup(ptv_avails, '_PanRegionalPayTV')\n",
    "ptv_local_avails, ptv_local_sales = cleanup(ptv_local_avails, '_LocalPayTV')\n",
    "\n",
    "ptv_avails = ptv_avails.merge(ptv_local_avails, on=list(ptv_avails.columns[:13]), how='left')\n",
    "merged_df = ptv_avails.merge(svod_avails, on=list(ptv_avails.columns[:13]), how='left')\n",
    "\n",
    "sales = svod_sales+ptv_sales+ptv_local_sales\n",
    "sales = [sale for sale in sales if not sale.startswith('_')]\n",
    "\n",
    "df = process(merged_df, sales, screeners, ratings)\n",
    "\n",
    "cols_ordered = ['Project Type', 'Unique Id', 'Title', 'Region', 'Year', 'Genre', 'Cast Member',\n",
    "                            'Director',  'Synopsis', 'Website',\n",
    "                            'Original Format', 'Dialogue Language', 'Subtitle Language',\n",
    "\n",
    "                            'First Run or Library_PanRegionalPayTV',\n",
    "                            'Available?_PanRegionalPayTV', 'Non-Exclusive Date_PanRegionalPayTV',\n",
    "                            'Exclusive Date_PanRegionalPayTV', 'Note_PanRegionalPayTV',\n",
    "                            'Holdback_PanRegionalPayTV',\n",
    "\n",
    "                            'First Run or Library_LocalPayTV',\n",
    "                            'Available?_LocalPayTV', 'Non-Exclusive Date_LocalPayTV',\n",
    "                            'Exclusive Date_LocalPayTV', 'Note_LocalPayTV',\n",
    "                            'Holdback_LocalPayTV',\n",
    "\n",
    "                            'First Run or Library_SVOD',\n",
    "                            'Available?_SVOD', 'Non-Exclusive Date_SVOD',\n",
    "                            'Exclusive Date_SVOD', 'Note_SVOD',\n",
    "                            'Holdback_SVOD',\n",
    "\n",
    "                            'Acq. Expires',\n",
    "                            'Link','Password', 'IMDB Link', 'US Box Office', 'LATAM Box Office', 'USA ',\n",
    "                            'Mexico', 'Brazil', ' Argentina', 'Bolivia', 'Chile', 'Colombia ',\n",
    "                            'Costa Rica', 'Ecuador', 'El Salvador', 'Guatemala', 'Honduras',\n",
    "                            'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'Dominican Republic',\n",
    "                            'Uruguay', 'Venezuela']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-27T18:37:06.535078Z",
     "start_time": "2021-02-27T18:37:06.132561Z"
    }
   },
   "outputs": [],
   "source": [
    "df[cols_ordered + sales].to_excel('/Users/alejandroleda/Documents/Ledafilms/Misc/Temp/SVOD-PayTV avails.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
